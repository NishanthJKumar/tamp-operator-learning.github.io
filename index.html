
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="bootstrap.js"></script>
<script type="text/javascript" charset="utf-8" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script> 
<!---
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
--->
<script src="load-mathjax.js" async></script>


<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
}

@media screen and (min-width: 980px){
    body {
        width: 980px;
    }
}


h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #5364cc;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1 {
    text-align: center;
}
h2,h3 {
    text-align: left;
}

h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
h3 {
    font-weight: 600;
    margin: 16px 0px 4px 0px;
}

.paper-title {
    padding: 1px 0px 1px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-5 {
     width: 20%;
     float: left;
}

.move-down {
    margin-top:0.4cm;
}

.move-up {
    margin-top:-0.3cm;
}

.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.col-1 {
     width: 100%;
     float: left;
}

.author-row, .affil-row {
    font-size: 26px;
}

.author-row-new { 
    text-align: center; 
}

.author-row-new a {
    display: inline-block;
    font-size: 22px;
    padding: 4px;
}

.author-row-new sup {
    color: #313436;
    font-size: 12px;
}

.affiliations-new {
    font-size: 18px;
    text-align: center;
    width: 80%;
    margin: 0 auto;
    margin-bottom: 20px;
}

.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 26px;
}
.affiliatons {
    font-size: 18px;
}
.affil-row {
    margin-top: 18px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0; 
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    color: #666;
    margin-top: 4px;
    margin-bottom: 10px;
	text-align: left;
}


video {
    display: block;
    margin: auto;
}


figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    padding: 0;
    margin: 0;
    list-style: none;
}

.paper-btn-coming-soon {
    position: relative; 
    top: 0;
    left: 0;
}

.coming-soon {
    position: absolute;
    top: -15px;
    right: -15px;
}

.center {
  margin-left: 10.0%;
  margin-right: 10.0%;
}

.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #5364cc;
  color: white !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}
.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.paper-btn:hover {
    opacity: 0.85;
}

.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}

.venue {
    font-size: 23px;
}

.topnav {
    background-color: #EEEEEE;
    overflow: hidden;
}

.topnav div {
    max-width: 1070px;
    margin: 0 auto;
}

.topnav a {
    display: inline-block;
    color: black;
    text-align: center;
    vertical-align: middle;
    padding: 16px 16px;
    text-decoration: none;
    font-size: 18px;
}

.topnav img {
    padding: 2px 0px;
    width: 100%;
    margin: 0.2em 0px 0.3em 0px;
    vertical-align: middle;
}

pre {
    font-size: 0.9em;
    padding-left: 7px;
    padding-right: 7px;
    padding-top: 3px;
    padding-bottom: 3px;
    border-radius: 3px;
    background-color: rgb(235, 235, 235);
    overflow-x: auto;
}

.download-thumb {
    display: flex;
}

@media only screen and (max-width: 620px) {
    .download-thumb {
        display: none;
    }
}

.paper-stuff {
    width: 50%;
    font-size: 20px;
}

@media only screen and (max-width: 620px) {
    .paper-stuff {
        width: 100%;
    }
}
* {
  box-sizing: border-box;
}

.column {
  text-align: center;
  float: left;
  width: 16.666%;
  padding: 5px;
}
.column3 {
  text-align: center;
  float: left;
  width: 33.333%;
  padding: 5px;
}
.column4 {
  text-align: center;
  float: left;
  width: 50%;
  padding: 5px;
}
.column5 {
  text-align: center;
  float: left;
  width: 20%;
  padding: 5px;
}
.column10 {
  text-align: center;
  float: left;
  width: 10%;
  padding: 5px;
}
.border-right {
    border-right: 1px solid black;
}
.border-bottom{
    border-bottom: 1px solid black;
}


.row-center {
    margin: 16px 0px 16px 0px;
    text-align: center;
}

/* Clearfix (clear floats) */
.row::after {
  content: "";
  clear: both;
  display: table;
}
.img-fluid {
  max-width: 100%;
  height: auto;
}
.figure-img {
  margin-bottom: 0.5rem;
  line-height: 1;
}








.rounded-circle {
  border-radius: 50% !important;
}






/* Responsive layout - makes the three columns stack on top of each other instead of next to each other */
@media screen and (max-width: 500px) {
  .column {
    width: 100%;
  }
}
@media screen and (max-width: 500px) {
  .column3 {
    width: 100%;
  }
}

</style>
<link rel="stylesheet" href="bootstrap-grid.css">

<script type="text/javascript" src="../js/hidebib.js"></script>
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
    <head>
        <title> https://fonts.googleapis.com/css2?family=Material+Icons</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:description" content="Overcoming the Pitfalls of Prediction Error in Operator Learning for Bilevel Planning"/>
        <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
    </head>

 <body>


<div class="container">
    <div class="paper-title">
    <h1> 
        Overcoming the Pitfalls of Prediction Error in Operator Learning for Bilevel Planning
    </div>

    <div id="authors">
        <center>
            <div class="author-row-new">
                <a href="http://nishanthjkumar.com/">Nishanth Kumar*<sup>1</sup></a>,
                <a href="https://wmcclinton.github.io/">Willie McClinton*<sup>1</sup></a>,
                <a href="https://rohanchitnis.com/">Rohan Chitnis<sup>2</sup></a>,
                <a href="https://web.mit.edu/tslvr/www/">Tom Silver<sup>2</sup></a>,
                <a href="https://people.csail.mit.edu/tlp/">Tom&aacute;s Lozano-P&#233;rez<sup>1</sup></a>,
                <a href="http://people.csail.mit.edu/lpk/">Leslie Kaelbling<sup>1</sup></a>.
            </div>
        </center>
        <center>
        <div class="affiliations">
            <span><sup>1</sup>MIT CSAIL</span>
            <span><sup>2</sup>Meta AI</span>
        </div>

        <br>*indicates equal contribution.

        <div class="affil-row">
            <div class="venue text-center"><b>arXiv 2023</b></div>
        </div>

        </center>

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="paper-btn" href="https://arxiv.org/abs/2208.07737">
                <span class="material-icons"> description </span> 
                 Paper
            </a>
            <div class="paper-btn-coming-soon">
                <a class="paper-btn" href="https://github.com/Learning-and-Intelligent-Systems/predicators_behavior/releases/tag/ijcai-23-submission">
                    <span class="material-icons"> code </span>
                    Code
                </a>
            </div>
        </div></div>
    </div>

    <section id="main-video">
        <center>
            <figure>
                <video class="centered" width="75%" controls="controls" preload="none" onclick="this.play()">
                    <source src="materials/main_video_nonanon.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </figure>

        </center>
    </section>

    <section id="abstract"/>
        <hr>
        <h2>Abstract</h2>
        <div class="flex-row">
            <p>
            Bilevel planning, in which a high-level search over an abstraction of an environment is used to guide low-level decision-making, is an effective approach to solving long-horizon tasks in continuous state and action spaces. Recent work has shown how to enable such bilevel planning by learning action and transition model abstractions in the form of symbolic operators and neural samplers. In this work, we show that existing symbolic operator learning approaches fall short in many natural environments where agent actions tend to cause a large number of irrelevant propositions to change. This is primarily because they attempt to learn operators that optimize the prediction error with respect to observed changes in the propositions. To overcome this issue, we propose to learn operators that only model changes necessary for abstract planning to achieve the specified goal. Experimentally, we show that our approach learns operators that lead to efficient planning across 10 different hybrid robotics domains, including 4 from the challenging BEHAVIOR-100 benchmark, with generalization to novel initial states, goals, and objects.
            </p>
        </div>
    </section>
        

    <section id="results">
        <hr>
        <h2>Combinatorial Generalization</h2>  
            <div class="flex-row">
                <p>	
                Below, we illustrate generated videos on unseen combinatorial combinations of goals. Our approach is able to
                synthesize a diverse set of different behaviors which satisfy unseen language subgoals.
                </p>
            </div> 

            <center>
            <figure>
                <video width="1000" loop autoplay muted>
                    <source src="materials/website_figure_1.mp4" type="video/mp4">
                </video>
            </figure>
            </center>

        <hr>


        <h2>Multitask Learning</h2>  
            <div class="flex-row">
                <p>
                Below, we illustrate generated videos on unseen tasks. Our approach is further able to synthesize a diverse set
                of different behaviors which satisfy unseen language tasks.
                </p>
            </div> 

            <center>
            <figure>
                <video width="1000" loop autoplay muted>
                    <source src="materials/website_figure_2.mp4" type="video/mp4">
                </video>
            </figure>
            </center>

        <hr>

        <h2>Real Robot Videos</h2>  
            <div class="flex-row">
                <p>Below, we further illustrate generated videos given language instructions on unseen real images. Our approach is
                able to synthesize a diverse set of different behaviors which satisfy language instructions.</p>
            </div> 

            <center>
            <figure>
                <video width="1000" loop autoplay muted>
                    <source src="materials/website_figure_3.mp4" type="video/mp4">
                </video>
            </figure>
            <figure>
                <div class="move-up">
                    <video width="1000" loop autoplay muted>
                        <source src="materials/website_figure_3_lower.mp4" type="video/mp4">
                    </video>
                </div>
            </figure>
            </center>

            <div class="flex-row">
                <p>Our approach is further able to generate videos of robot behaviors given unseen natural language
                instructions. Note that pretraining on a large online dataset of text/videos significantly helps 
                generalization to unseen natural language queries.
                </p>
            </div> 

            <center>
            <figure>
                <video width="700" loop autoplay muted>
                    <source src="materials/website_figure_4.mp4" type="video/mp4">
                </video>
            </figure>
            </center>

        <hr>

    </section> 

    <section id="related_projects">
        <hr>
        <h2>Related Resources</h2>

          <br>
          Check out other recent work on leveraging foundation models for decision making at the FMDM workshop.
          <br>
        <div class="row vspace-top">
        <div class="col-sm-3">
            <div class="move-down">
                <img src="materials/related/fmdm.png" class="img-fluid" alt="dd" style="width:100%">
            </div>
        </div>
        <div class="col-sm-9">
          <div class="paper-title">
            <a href="https://sites.google.com/corp/view/fmdm-neurips/">Foundation Models for Decision Making NeurIPS2022 Workshop</a>
        </div>
          <div>
	    The FMDM workshop brings together the decision making community and the foundation models community in vision and language to confront the challenges in decision making at scale. <a href="https://nips.cc/virtual/2022/workshop/49988">Recordings</a>.

        </div>
        </div>
        </div>	

          <br>
          Check out a list of our related papers on leverage generative models for decision making.
          <br>

        <div class="row vspace-top">
        <div class="col-sm-3">
            <div class="move-down">
                <img src="materials/related/dd.png" class="img-fluid" alt="dd" style="width:100%">
            </div>
        </div>
        <div class="col-sm-9">
          <div class="paper-title">
            <a href="https://anuragajay.github.io/decision-diffuser/">Is Conditional Generative Modeling All You Need for Decision-Making?</a>
        </div>
        <div>
            We illustrate how conditional generative modeling is a powerful paradigm for decision-making, enabling us
            utilize a reward conditional model to effectively perform offline RL. We further illustrate how conditional generative modeling enables
            us to compose multiple different constraints and skills together.
        </div>
        </div>
        </div>

        <div class="row vspace-top">
        <div class="col-sm-3">
            <div class="move-down">
                <video width="100%" playsinline="" autoplay="" loop="" preload="" muted="">
                    <source src="materials/related/diffuser.mp4" type="video/mp4">
                </video>
            </div>
        </div>
        <div class="col-sm-9">
          <div class="paper-title">
            <a href="https://diffusion-planning.github.io/">Planning with Diffusion for Flexible Behavior Synthesis </a>
        </div>
        <div>
            We illustrate how may utilize a trajectory level diffusion model as an effective data-driven planner. We
            illustrate how this planner enables us to flexibly generate long sequences of actions subject novel goals and 
            constraints as well as perform effective offline RL. 
        </div>
        </div>
        </div>


    </section> 

    <section>
        This webpage template was recycled from <a href='https://nv-tlabs.github.io/LION/'>here</a>.
    </section>

</div>
</body>
</html>
